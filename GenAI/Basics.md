# Understanding Deep Learning, Neural Networks & LLM Architecture

## Overview

To deeply understand how LLMs work, you need to first understand neural networks and deep learning. And to grasp deep learning, you need a solid foundation in machine learning.

While this deep knowledge isn't necessary and is often overkill for most AI roles, it becomes essential if you're working on modifying model architectures or building models from scratch. That said, very few companies develop models from scratch today—a lot can be achieved with strong application-level knowledge, which is the core focus of this course.

Think of it like understanding how the web works and coding websites versus using those websites to build online businesses. AI is reaching that level of pervasiveness today.

If at any point you want to dive deep into this field, there’s a long learning roadmap with our favorite recommendations below (Takes 80-100 hours or more!). However, if your goal is practical, application-level knowledge, a shorter roadmap (last section) can still give you enough understanding to work with LLMs effectively.

---

## Learning Roadmaps

### Long Learning Roadmap (80–100+ hours)
Recommended for a **deep understanding of LLMs**:

1. **Machine Learning** – Builds the foundation for deep learning  
   - [Andrew Ng’s Machine Learning Course](https://www.coursera.org/learn/machine-learning)

2. **Deep Learning** – Essential for understanding neural networks  
   - [Deep Learning Specialization on Coursera](https://www.coursera.org/specializations/deep-learning)

3. **NLP Basics** – Covers RNNs, transformers, and attention  
   - [Stanford CS224N - NLP with Deep Learning](http://web.stanford.edu/class/cs224n/)

4. **LLM Architecture and Training** – Covers large-scale model training and fine-tuning  
   - [Stanford CS25 - Transformers United](https://cs25.github.io/)

5. **Building LLMs from the Ground Up** – A 3-hour coding workshop  
   - [Workshop Link](https://www.youtube.com/watch?v=quh7z1q7-uc) 

> This path is recommended for those who want to understand LLMs **under the hood**.

---

### Shorter Learning Roadmap (2–3 hours)
For a **practical, application-level understanding** of LLMs and transformers:

- [Jay Alammar’s Illustrated Transformers](http://jalammar.github.io/illustrated-transformer/)  
- [Andrej Karpathy’s Video on LLM Training – LLMs: Training & Fine-Tuning](https://www.youtube.com/watch?v=kCc8FmEb1nY)  
- [Illustrating Reinforcement Learning from Human Feedback (RLHF) – HuggingFace](https://huggingface.co/blog/rlhf)

> This shorter path won’t make you an ML or deep learning expert but gives a solid grasp of LLMs for practical use.

---