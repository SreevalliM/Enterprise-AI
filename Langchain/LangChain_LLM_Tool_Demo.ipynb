{"cells":[{"cell_type":"markdown","metadata":{"id":"zoeWzTx4DHUm"},"source":["# LLMs and their tools\n","\n","## Objective:\n","LLMs don't execute tools directly - they only decide which tools to use and parse arguments. The actual tool execution happens in separate code.\n","\n","This notebook compares two approaches for integrating tools with LLMs:\n","\n","1. Manual Tool Chaining (explicit parsing/execution)\n","\n","2. llm.bind_tools() (automatic tool-call binding).\n","\n","With bind_tools(), this process is automated through structured outputs, while manual chaining gives you control by parsing text responses like 'TOOL: calculator|2+2' and routing to functions yourself.\n","\n","We’ll explore the trade-offs between these methods, including how each interacts with RunnableWithMessageHistory for stateful conversations. Below is a high-level comparison:\n","\n","| Aspect               | Manual Tool Chaining                        | `bind_tools()`                                   |\n","|----------------------|---------------------------------------------|--------------------------------------------------|\n","| **Code Clarity**     | More complex, error-prone parsing           | Cleaner, automatic JSON-based tool calls         |\n","| **Tool Execution**   | Manual (logic in prompts/code)              | Decoupled: LLM suggests calls, code executes     |\n","| **Memory Support**   | Native via message history wrapper          | Requires manual tool-result logging              |\n","| **Flexibility**      | Full control over workflow                  | Structured (limited by API design)               |\n","| **Best For**         | Custom workflows, complex logic             | Rapid development, standardized tooling          |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0o6Dq5bvDHUp","outputId":"d16e0603-8e76-439d-dd0c-54ada08c03c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain==0.3.25\n","  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n","Collecting langgraph==0.4.5\n","  Downloading langgraph-0.4.5-py3-none-any.whl.metadata (7.3 kB)\n","Collecting langchain-openai==0.3.18\n","  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n","Collecting python-dotenv==1.1.0\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting gradio==5.17.1\n","  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n","Collecting langchain-core<1.0.0,>=0.3.58 (from langchain==0.3.25)\n","  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n","Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain==0.3.25)\n","  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (0.3.14)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (2.10.6)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (2.0.39)\n","Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain==0.3.25) (4.0.3)\n","Collecting langgraph-checkpoint<3.0.0,>=2.0.26 (from langgraph==0.4.5)\n","  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n","Collecting langgraph-prebuilt>=0.1.8 (from langgraph==0.4.5)\n","  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: langgraph-sdk>=0.1.42 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langgraph==0.4.5) (0.1.57)\n","Collecting xxhash<4.0.0,>=3.5.0 (from langgraph==0.4.5)\n","  Downloading xxhash-3.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n","Collecting openai<2.0.0,>=1.68.2 (from langchain-openai==0.3.18)\n","  Downloading openai-1.86.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain-openai==0.3.18) (0.9.0)\n","Collecting aiofiles<24.0,>=22.0 (from gradio==5.17.1)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (4.8.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.115.11)\n","Collecting ffmpy (from gradio==5.17.1)\n","  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.7.1 (from gradio==5.17.1)\n","  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.29.3)\n","Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (3.1.6)\n","Collecting markupsafe~=2.0 (from gradio==5.17.1)\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (2.2.3)\n","Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (3.10.15)\n","Requirement already satisfied: packaging in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (2.2.3)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (11.1.0)\n","Collecting pydub (from gradio==5.17.1)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio==5.17.1)\n","  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Collecting ruff>=0.9.3 (from gradio==5.17.1)\n","  Downloading ruff-0.11.13-py3-none-macosx_10_12_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.17.1)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio==5.17.1)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.46.1)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.17.1)\n","  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.15.2)\n","Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio==5.17.1) (0.34.0)\n","Requirement already satisfied: fsspec in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from gradio-client==1.7.1->gradio==5.17.1) (2025.3.0)\n","Collecting websockets<15.0,>=10.0 (from gradio-client==1.7.1->gradio==5.17.1)\n","  Downloading websockets-14.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.17.1) (1.2.2)\n","Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.17.1) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.17.1) (1.3.1)\n","Requirement already satisfied: certifi in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from httpx>=0.24.1->gradio==5.17.1) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from httpx>=0.24.1->gradio==5.17.1) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.17.1) (0.14.0)\n","Requirement already satisfied: filelock in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio==5.17.1) (3.18.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio==5.17.1) (4.67.1)\n","Collecting langsmith<0.4,>=0.1.17 (from langchain==0.3.25)\n","  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain==0.3.25) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain==0.3.25) (1.33)\n","Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph==0.4.5)\n","  Downloading ormsgpack-1.10.0-cp310-cp310-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (43 kB)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.25) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.25) (0.23.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.18) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.18) (0.8.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==5.17.1) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==5.17.1) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==5.17.1) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.25) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.25) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.25) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.25) (2.3.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.25) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.18) (2024.11.6)\n","Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.17.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.17.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.17.1) (13.9.4)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain==0.3.25) (3.0.0)\n","Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.17.1) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.17.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.17.1) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/ai-interview-python/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.17.1) (0.1.2)\n","Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.4.5-py3-none-any.whl (155 kB)\n","Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading gradio-5.17.1-py3-none-any.whl (62.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.7.1-py3-none-any.whl (321 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n","Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n","Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n","Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n","Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n","Downloading MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl (14 kB)\n","Downloading openai-1.86.0-py3-none-any.whl (730 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.3/730.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.13-py3-none-macosx_10_12_x86_64.whl (11.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\n","Downloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading ormsgpack-1.10.0-cp310-cp310-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (376 kB)\n","Downloading websockets-14.2-cp310-cp310-macosx_10_9_x86_64.whl (160 kB)\n","Installing collected packages: pydub, xxhash, websockets, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, ormsgpack, markupsafe, ffmpy, aiofiles, safehttpx, openai, langsmith, gradio-client, langchain-core, gradio, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain, langgraph\n","  Attempting uninstall: websockets\n","    Found existing installation: websockets 15.0\n","    Uninstalling websockets-15.0:\n","      Successfully uninstalled websockets-15.0\n","  Attempting uninstall: python-dotenv\n","    Found existing installation: python-dotenv 1.0.1\n","    Uninstalling python-dotenv-1.0.1:\n","      Successfully uninstalled python-dotenv-1.0.1\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.66.5\n","    Uninstalling openai-1.66.5:\n","      Successfully uninstalled openai-1.66.5\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.3.14\n","    Uninstalling langsmith-0.3.14:\n","      Successfully uninstalled langsmith-0.3.14\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.45\n","    Uninstalling langchain-core-0.3.45:\n","      Successfully uninstalled langchain-core-0.3.45\n","  Attempting uninstall: langgraph-checkpoint\n","    Found existing installation: langgraph-checkpoint 2.0.20\n","    Uninstalling langgraph-checkpoint-2.0.20:\n","      Successfully uninstalled langgraph-checkpoint-2.0.20\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.6\n","    Uninstalling langchain-text-splitters-0.3.6:\n","      Successfully uninstalled langchain-text-splitters-0.3.6\n","  Attempting uninstall: langchain-openai\n","    Found existing installation: langchain-openai 0.3.8\n","    Uninstalling langchain-openai-0.3.8:\n","      Successfully uninstalled langchain-openai-0.3.8\n","  Attempting uninstall: langgraph-prebuilt\n","    Found existing installation: langgraph-prebuilt 0.1.3\n","    Uninstalling langgraph-prebuilt-0.1.3:\n","      Successfully uninstalled langgraph-prebuilt-0.1.3\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.20\n","    Uninstalling langchain-0.3.20:\n","      Successfully uninstalled langchain-0.3.20\n","  Attempting uninstall: langgraph\n","    Found existing installation: langgraph 0.3.11\n","    Uninstalling langgraph-0.3.11:\n","      Successfully uninstalled langgraph-0.3.11\n","Successfully installed aiofiles-23.2.1 ffmpy-0.6.0 gradio-5.17.1 gradio-client-1.7.1 langchain-0.3.25 langchain-core-0.3.65 langchain-openai-0.3.18 langchain-text-splitters-0.3.8 langgraph-0.4.5 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langsmith-0.3.45 markupsafe-2.1.5 openai-1.86.0 ormsgpack-1.10.0 pydub-0.25.1 python-dotenv-1.1.0 python-multipart-0.0.20 ruff-0.11.13 safehttpx-0.1.6 semantic-version-2.10.0 tomlkit-0.13.3 websockets-14.2 xxhash-3.5.0\n"]}],"source":["! pip install langchain==0.3.25 langgraph==0.4.5 langchain-openai==0.3.18 python-dotenv==1.1.0 gradio==5.17.1"]},{"cell_type":"markdown","metadata":{"id":"egHVRj_BDHUr"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jsvz8rjpDHUr"},"outputs":[],"source":["## Common Setup\n","import os\n","from datetime import datetime\n","# Load environment variables\n","from dotenv import load_dotenv\n","from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.tools import tool\n","from langchain_openai import ChatOpenAI\n","from langchain_core.chat_history import BaseChatMessageHistory\n","from langchain_core.messages import BaseMessage\n","from pydantic import BaseModel, Field\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","from langchain_core.runnables import RunnableLambda\n","\n","import logging\n","\n","load_dotenv()\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)\n","\n","\n","# Shared tool definitions\n","@tool\n","def calculator_tool(expression: str) -> float:\n","    \"\"\"Calculate mathematical expressions safely.\"\"\"\n","    try:\n","        # Simple safe evaluation (in production, use a proper math parser)\n","        result = eval(expression.replace(\"^\", \"**\"))\n","        return float(result)\n","    except:\n","        return \"Error: Invalid expression\"\n","\n","\n","@tool\n","def get_current_time(format_str: str = \"%Y-%m-%d %H:%M:%S\") -> str:\n","    \"\"\"Get current date and time in specified format.\"\"\"\n","    return datetime.now().strftime(format_str)\n"]},{"cell_type":"markdown","metadata":{"id":"3ibd1Fj-DHUs"},"source":["## Lets compare Manual Chaining vs Bind tools"]},{"cell_type":"markdown","metadata":{"id":"O9vjVFN-DHUs"},"source":["## Approach 1 : Manual Chaining"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXtsrwK9DHUs"},"outputs":[],"source":["# Initialize LLM\n","llm_for_manual_chain = ChatOpenAI(temperature=0)\n","\n","# Step 1: Define prompt template for tool selection\n","prompt_for_llm_for_manual_chain = ChatPromptTemplate.from_template(\n","    \"\"\"Analyze the user's question and decide if tools are needed.\n","    Available tools:\n","    - calculator_tool: For math operations (input: math expression)\n","    - get_current_time: Returns current time (input: time format string)\n","\n","    Respond EXACTLY in one of these formats:\n","\n","    TOOL: calculator_tool|2+2\n","    TOOL: get_current_time|%Y-%m-%d\n","    ANSWER: direct_answer (e.g., \"ANSWER: The capital of France is Paris\")\n","\n","    User question: {question}\"\"\"\n",")\n","\n","# Tool mapping dictionary\n","tool_map = {\n","    'calculator_tool': calculator_tool,\n","    'get_current_time': get_current_time\n","}\n","\n","def execute_tools_for_manual_chain(response: AIMessage) -> str:\n","    \"\"\"Execute tools based on LLM response or return direct answer.\"\"\"\n","    content = response.content\n","    print(content)\n","\n","    if content.startswith(\"TOOL:\"):\n","        try:\n","            # Parse tool call\n","            _, tool_call = content.split(\":\", 1)\n","            tool_name, args = tool_call.strip().split(\"|\")\n","\n","            # Execute tool\n","            tool = tool_map[tool_name]\n","            result = tool.invoke(args.strip())\n","            return f\"{result}\"\n","\n","        except Exception as e:\n","            return f\"Error executing tool: {str(e)}\"\n","\n","    elif content.startswith(\"ANSWER:\"):\n","        # Return direct answer\n","        return content.split(\":\", 1)[1].strip()\n","\n","    else:\n","        return \"I couldn't process your request properly.\"\n","\n","# Step 2: Create the chain\n","manual_chain = (\n","    prompt_for_llm_for_manual_chain\n","    | llm_for_manual_chain\n","    | RunnableLambda(execute_tools_for_manual_chain)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvudQiSgDHUt","outputId":"d161ff75-1abc-4862-96b1-e3005b90239b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: What's today's date?\n","TOOL: get_current_time|%Y-%m-%d\n","Response: 2025-06-10\n","\n","Query: What's 4+4?\n","TOOL: calculator_tool|4+4\n","Response: 8.0\n","\n","Query: What's captial of UK\n","ANSWER: The capital of the UK is London.\n","The capital of the UK is London.\n"]}],"source":["# Test 1: Date query\n","print(\"Query: What's today's date?\")\n","response = manual_chain.invoke({\"question\": \"What's today's date?\"})\n","print(f\"Response: {response}\\n\")\n","\n","# Test 2: Math query\n","print(\"Query: What's 4+4?\")\n","response = manual_chain.invoke({\"question\": \"What's 4+4?\"})\n","print(f\"Response: {response}\\n\")\n","\n","# Non tool call\n","print(\"Query: What's captial of UK\")\n","response3 = manual_chain.invoke({\"question\":\"What's captial of UK\"})\n","print(response3)"]},{"cell_type":"markdown","metadata":{"id":"lPUhk6I9DHUu"},"source":["## Approach 2 : LLM for bind tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXDqfpyADHUu"},"outputs":[],"source":["import json\n","\n","llm_with_bind_tools = ChatOpenAI(temperature=0)\n","tools = [calculator_tool, get_current_time]\n","prompt_for_llm_with_bind_tools = ChatPromptTemplate.from_template(\n","    \"\"\"Analyze the user's question and use if tools are needed. Otherwise just answer the question\n","    User question: {question}\"\"\"\n",")\n","\n","# Tool mapping dictionary\n","tool_map = {\n","    'calculator_tool': calculator_tool,\n","    'get_current_time': get_current_time\n","}\n","\n","def execute_tools_for_bind_tools(response: AIMessage) -> str:\n","    \"\"\"Execute tools based on LLM response or return direct answer.\"\"\"\n","    tool_calls = response.additional_kwargs.get(\"tool_calls\", [])\n","\n","    for call in tool_calls:\n","        function_call = call['function']\n","        # Correct way to get tool name and arguments\n","        tool_name = function_call[\"name\"]\n","        tool_args = json.loads(function_call[\"arguments\"])\n","\n","        # Run the tool manually with keyword args unpacked\n","        if tool_name == \"calculator_tool\":\n","            output = calculator_tool.invoke(input=tool_args)\n","        elif tool_name == \"get_current_time\":\n","            output = get_current_time.invoke(input=tool_args)\n","        else:\n","            output = \"Tool not found.\"\n","        return output\n","    return response.content\n","\n","\n","# Step 2: Create the chain\n","bind_tools_chain = (\n","    prompt_for_llm_with_bind_tools\n","    | llm_with_bind_tools.bind_tools(tools) | RunnableLambda(execute_tools_for_bind_tools)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fi0eUIXDHUu","outputId":"2c156b75-0d61-49d8-bc78-5d18ae1564d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: What's today's date?\n","Response: 2025-06-10 23:51:58\n","\n","Query: What's 4+4?\n","Response: 8.0\n","\n","Query: What's captial of UK\n","The capital of the UK is London.\n"]}],"source":["# Test 1: Date query\n","print(\"Query: What's today's date?\")\n","response = bind_tools_chain.invoke({\"question\": \"What's today's date?\"})\n","print(f\"Response: {response}\\n\")\n","\n","# Test 2: Math query\n","print(\"Query: What's 4+4?\")\n","response = bind_tools_chain.invoke({\"question\": \"What's 4+4?\"})\n","print(f\"Response: {response}\\n\")\n","\n","# Non tool call\n","print(\"Query: What's captial of UK\")\n","response3 = bind_tools_chain.invoke({\"question\":\"What's captial of UK\"})\n","print(response3)"]},{"cell_type":"markdown","metadata":{"id":"Q5K8ET8KDHUv"},"source":["## 3. Adding Memory to Manual Chain and Bind Tools Chain"]},{"cell_type":"markdown","metadata":{"id":"79zc5yVhDHUv"},"source":["### Adding Memory to Manual Chain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIptOnoUDHUv"},"outputs":[],"source":["from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","class ManualToolChaining:\n","    \"\"\"Explicit tool handling with manual chaining and session memory.\"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Initialize with the pre-built manual chain.\"\"\"\n","        self.prompt = ChatPromptTemplate.from_messages([\n","            (\"system\", \"\"\"You are a helpful assistant that MUST follow the exact response format.\n","\n","        Available tools:\n","        - calculator_tool: For mathematical calculations (any math expression)\n","        - get_current_time: For current date/time (use format like %Y-%m-%d %H:%M:%S)\n","\n","        CRITICAL: You MUST respond in EXACTLY one of these formats:\n","\n","        For tool usage:\n","        Always use all caps TOOL\n","        TOOL: calculator_tool|2+2\n","        TOOL: get_current_time|%Y-%m-%d %H:%M:%S\n","\n","        For direct answers:\n","        ANSWER: Your direct response here\n","\n","        EXAMPLES:\n","        - User asks \"What's the date?\" → Respond: \"TOOL: get_current_time|%Y-%m-%d\"\n","        - User asks \"What's 5+3?\" → Respond: \"TOOL: calculator_tool|5+3\"\n","        - User asks \"What's the capital of France?\" → Respond: \"ANSWER: The capital of France is Paris\"\n","        - User asks about previous conversation → Look at the conversation history and respond: \"ANSWER: [summary of what they asked]\"\n","\n","        DO NOT give conversational responses like \"I can help you with that\" - use the exact format above.\"\"\"),\n","                    MessagesPlaceholder(variable_name=\"history\"),\n","                    (\"human\", \"{question}\")\n","                ])\n","\n","        self.manual_chain = self.prompt | llm_for_manual_chain | RunnableLambda(execute_tools_for_manual_chain)\n","        self.store = {}\n","\n","    def get_session_history(self, session_id: str) -> BaseChatMessageHistory:\n","        \"\"\"Get or create session history for the given session ID.\"\"\"\n","        if session_id not in self.store:\n","            self.store[session_id] = ChatMessageHistory()\n","        return self.store[session_id]\n","\n","    def process_message(self, message: str, session_id: str = \"default\") -> str:\n","        \"\"\"Process message with manual tool chaining and memory.\"\"\"\n","        try:\n","            chain_with_memory = RunnableWithMessageHistory(\n","                self.manual_chain,\n","                self.get_session_history,\n","                input_messages_key=\"question\",\n","                history_messages_key=\"history\"\n","            )\n","\n","            # Invoke the chain\n","            response = chain_with_memory.invoke(\n","                {\"question\": message},\n","                config={\"configurable\": {\"session_id\": session_id}}\n","            )\n","\n","            return response\n","\n","        except Exception as e:\n","            return f\"Error processing message: {str(e)}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2c7eTikDHUv","outputId":"cd4e0f2b-b7d3-4de1-9263-437d307f70f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: What's today's date?\n","TOOL: get_current_time|%Y-%m-%d %H:%M:%S\n","Response: 2025-06-10 23:52:02\n","\n","Query: What's 4+4?\n","TOOL: calculator_tool|4+4\n","Response: 8.0\n","\n","Query: Add 4 to previous answer\n","TOOL: calculator_tool|8+4\n","12.0\n"]}],"source":["manual_chain_with_memory = ManualToolChaining()\n","# Test 1: Date query\n","print(\"Query: What's today's date?\")\n","response = manual_chain_with_memory.process_message(message =\"What's date\", session_id =\"manual_session\")\n","print(f\"Response: {response}\\n\")\n","\n","# Test 2: Math query\n","print(\"Query: What's 4+4?\")\n","response = manual_chain_with_memory.process_message(message =\"What's 4+4?\", session_id =\"manual_session\")\n","print(f\"Response: {response}\\n\")\n","\n","# Non tool call\n","print(\"Query: Add 4 to previous answer\")\n","response = manual_chain_with_memory.process_message(message =\"Add 4 to previous answer\", session_id =\"manual_session\")\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"gvJ0ZI0vDHUw"},"source":["### Adding Memory to Bind Tools Chain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"884Bu1WfDHUw"},"outputs":[],"source":["import json\n","from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n","\n","class AutomaticToolBinding:\n","    \"\"\"Auto tool handling + manual tool execution + resumed response.\"\"\"\n","\n","    def __init__(self):\n","        self.prompt = ChatPromptTemplate.from_messages([\n","            (\"system\", \"You are a helpful assistant with tools. Use them when needed.\"),\n","            MessagesPlaceholder(variable_name=\"history\"),\n","            (\"human\", \"{question}\")\n","        ])\n","        self.bind_tools_chain = self.prompt |  llm_with_bind_tools.bind_tools(tools)\n","        self.store = {}\n","\n","    def get_session_history(self, session_id: str) -> BaseChatMessageHistory:\n","        if session_id not in self.store:\n","            self.store[session_id] = InMemoryHistory()\n","        return self.store[session_id]\n","\n","\n","    def process_message(self, message: str, session_id: str = \"default\") -> str:\n","\n","        chain_with_memory = RunnableWithMessageHistory(\n","            self.bind_tools_chain ,\n","            self.get_session_history,\n","            input_messages_key=\"question\",\n","            history_messages_key=\"history\"\n","        )\n","\n","        # Step 1: Get model's initial response\n","        response = chain_with_memory.invoke(\n","            {\"question\": message},\n","            config={\"configurable\": {\"session_id\": session_id}}\n","        )\n","\n","        tool_calls = response.additional_kwargs.get(\"tool_calls\", [])\n","        history = self.get_session_history(session_id=session_id)\n","\n","        if tool_calls:\n","            tool_messages = []\n","\n","            for call in tool_calls:\n","                function_call = call['function']\n","                # Correct way to get tool name and arguments\n","                tool_name = function_call[\"name\"]\n","                tool_args = json.loads(function_call[\"arguments\"])\n","                tool_id = call[\"id\"]\n","\n","                # Run the tool manually with keyword args unpacked\n","                if tool_name == \"calculator_tool\":\n","                    output = calculator_tool.invoke(input=tool_args)\n","                elif tool_name == \"get_current_time\":\n","                    output = get_current_time.invoke(input=tool_args)\n","                else:\n","                    output = \"Tool not found.\"\n","\n","                # Wrap tool output into ToolMessage\n","                tool_msg = ToolMessage(tool_call_id=tool_id, content=str(output))\n","                tool_messages.append(tool_msg)\n","                history.add_message(tool_msg)\n","\n","            # Step 2: Feed tool outputs back into model\n","            followup = llm_with_bind_tools.invoke([\n","                HumanMessage(content=message),\n","                response,\n","                *tool_messages\n","            ])\n","            return followup.content\n","        else:\n","            return response.content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rt5lJSzaDHUw","outputId":"84e1066a-6904-4f56-87d4-3a9a8964337e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: What's today's date?\n","Response: The current date is June 10, 2025.\n","\n","Query: What's 4+4?\n","Response: 4 + 4 equals 8.\n","\n","Query: Add 4 to previous answer\n","The result of adding 4 to the previous answer is 12.\n"]}],"source":["bind_tools_chain_with_memory = AutomaticToolBinding()\n","# Test 1: Date query\n","print(\"Query: What's today's date?\")\n","response = bind_tools_chain_with_memory.process_message(message =\"What's date\", session_id =\"manual_session\")\n","print(f\"Response: {response}\\n\")\n","\n","# Test 2: Math query\n","print(\"Query: What's 4+4?\")\n","response = bind_tools_chain_with_memory.process_message(message =\"What's 4+4?\", session_id =\"manual_session\")\n","print(f\"Response: {response}\\n\")\n","\n","# Non tool call\n","print(\"Query: Add 4 to previous answer\")\n","response = bind_tools_chain_with_memory.process_message(message =\"Add 4 to previous answer\", session_id =\"manual_session\")\n","print(response)"]}],"metadata":{"kernelspec":{"display_name":"ai-interview-python","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}